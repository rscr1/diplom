{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "from pathlib import Path\n",
    "#from pprint import pprint\n",
    "\n",
    "import fiftyone as fo\n",
    "import fiftyone.brain as fob\n",
    "import fiftyone.core.utils as fou\n",
    "#import fiftyone.types\n",
    "import fiftyone.utils.random as four\n",
    "import fiftyone.zoo as foz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "#from custom_plotly_templates import set_render_config, set_template\n",
    "from fiftyone import ViewField as F\n",
    "#from fiftyone.utils.image import transform_images\n",
    "from fiftyone.utils.iou import compute_max_ious\n",
    "#from omegaconf import OmegaConf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.list_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Download dataset\n",
    "\n",
    "# foz.load_zoo_dataset(\n",
    "#     name=\"road_detection\",\n",
    "#     dataset_name=\"road_detection\",\n",
    "#     dataset_dir=dataset_dir,\n",
    "#     cleanup=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fo.delete_dataset('road_segmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = fo.load_dataset('road_segmentation')\n",
    "# print(dataset.view())\n",
    "# print(dataset.stats(include_media=True))\n",
    "# session = fo.launch_app(dataset)\n",
    "# session.open_tab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка датасета детекции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = \"roads_detection3\"\n",
    "dataset_dir = r'/root/storage/3030/AkhmetzyanovD/datasets/roads/datasets/det'\n",
    "overwrite = True\n",
    "# The splits to load\n",
    "splits = [\"train\", \"val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### YOLO dataset\n",
    "if not overwrite and fo.dataset_exists(dataset_name):\n",
    "    dataset = fo.load_dataset(dataset_name)\n",
    "else:\n",
    "    if fo.dataset_exists(dataset_name):\n",
    "        fo.delete_dataset(dataset_name)\n",
    "    dataset = fo.Dataset(dataset_name)\n",
    "    for split in splits:\n",
    "        dataset.add_dir(\n",
    "            dataset_dir=dataset_dir,\n",
    "            dataset_type=fo.types.YOLOv5Dataset,\n",
    "            split=split,\n",
    "            tags=split,\n",
    "    )\n",
    "    dataset.persistent = True\n",
    "    \n",
    "print(dataset.view())\n",
    "print(dataset.stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset)\n",
    "session.open_tab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка датасета сегментации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = r'/AkhmetzyanovD/datasets/roads2/dataset3/train.txt'\n",
    "valid_paths = r'/AkhmetzyanovD/datasets/roads2/dataset3/train.txt'\n",
    "\n",
    "dataset_name = 'road_segmentation3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fo.Dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_paths, 'r') as train_file:\n",
    "    for paths in train_file.readlines():\n",
    "        image_path, mask_path = paths.split()\n",
    "\n",
    "        sample = fo.Sample(filepath=image_path)\n",
    "        sample[\"segmentation\"] = fo.Segmentation(mask_path=mask_path)\n",
    "        sample['tags'] = ['train']\n",
    "        dataset.add_sample(sample)\n",
    "    train_file.close()\n",
    "\n",
    "with open(valid_paths, 'r') as valid_file:\n",
    "    for paths in valid_file.readlines():\n",
    "        image_path, mask_path = paths.split()\n",
    "\n",
    "        sample = fo.Sample(filepath=image_path)\n",
    "        sample[\"segmentation\"] = fo.Segmentation(mask_path=mask_path)\n",
    "        sample['tags'] = ['valid']\n",
    "        dataset.add_sample(sample)\n",
    "    valid_file.close()\n",
    "\n",
    "print(dataset.view())\n",
    "print(dataset.stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset)\n",
    "session.open_tab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OTHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fo.Dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add dir\n",
    "for split in splits:\n",
    "        dataset.add_dir(\n",
    "            dataset_dir=dataset_dir,\n",
    "            dataset_type=fo.types.YOLOv5Dataset,\n",
    "            split=split,\n",
    "            tags=split,\n",
    "    )\n",
    "dataset.persistent = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = dataset.view()\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COCO dataset\n",
    "data_path = \"/workspace/storage/3030/VoynovD/dump/data/extrabird/mva2023_sod4bird_pub_test/images\"\n",
    "labels_path = \"/workspace/storage/3030/VoynovD/dump/data/extrabird/mva2023_sod4bird_pub_test/annotations/public_test_coco_empty_ann.json\"\n",
    "\n",
    "if not overwrite and fo.dataset_exists(dataset_name):\n",
    "    dataset = fo.load_dataset(dataset_name)\n",
    "else:\n",
    "    if fo.dataset_exists(dataset_name):\n",
    "        fo.delete_dataset(dataset_name)\n",
    "\n",
    "    dataset = fo.Dataset.from_dir(\n",
    "        name=dataset_name,\n",
    "        #dataset_dir=dataset_dir,\n",
    "        data_path=data_path,\n",
    "        labels_path=labels_path,\n",
    "        dataset_type=fo.types.COCODetectionDataset,\n",
    "        #label_types=[\"detections\"]\n",
    "    )\n",
    "    dataset.persistent = True\n",
    "\n",
    "view = dataset.view()\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = ['DD', 'E', 'G', 'I', 'K', 'PB', 'PB_glasses', 'PY', 'S', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add dir\n",
    "for dir in dirs:\n",
    "    dataset.add_dir(\n",
    "        data_path=f\"/workspace/storage/3030/VoynovD/integral/Eye_keypoint_detector/EKD/images/{dir}\",\n",
    "        labels_path=f\"/workspace/storage/3030/VoynovD/integral/Eye_keypoint_detector/EKD/labels/{dir}/annotations/person_keypoints_default.json\",\n",
    "        dataset_type=fo.types.COCODetectionDataset,\n",
    "    )\n",
    "dataset.persistent = True\n",
    "view = dataset.view()\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### KITI dataset\n",
    "if not overwrite and fo.dataset_exists(dataset_name):\n",
    "    dataset = fo.load_dataset(dataset_name)\n",
    "else:\n",
    "    if fo.dataset_exists(dataset_name):\n",
    "        fo.delete_dataset(dataset_name)\n",
    "\n",
    "    dataset = fo.Dataset.from_dir(\n",
    "        name=dataset_name,\n",
    "        dataset_dir=dataset_dir,\n",
    "        dataset_type=fo.types.KITTIDetectionDataset,\n",
    "    )\n",
    "    dataset.persistent = True\n",
    "\n",
    "view = dataset.view()\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### VOC\n",
    "dataset_name = \"heridal\"\n",
    "dataset_dir = \"/workspace/storage/db/emergency-search/heridal/raw\"\n",
    "overwrite = True\n",
    "# The splits to load\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "# Create the dataset\n",
    "# dataset = fo.Dataset.from_dir(\n",
    "#     dataset_dir=dataset_dir,\n",
    "#     dataset_type=fo.types.VOCDetectionDataset,\n",
    "#     name=name,\n",
    "# )\n",
    "\n",
    "if not overwrite and fo.dataset_exists(dataset_name):\n",
    "    dataset = fo.load_dataset(dataset_name)\n",
    "else:\n",
    "    if fo.dataset_exists(dataset_name):\n",
    "        fo.delete_dataset(dataset_name)\n",
    "    dataset = fo.Dataset(dataset_name)\n",
    "    for split in splits:\n",
    "        dataset.add_dir(\n",
    "            dataset_dir=f'{dataset_dir}/{split}',\n",
    "            dataset_type=fo.types.VOCDetectionDataset,\n",
    "            tags=split,\n",
    "    )\n",
    "    dataset.persistent = True\n",
    "    \n",
    "view = dataset.view()\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.persistent = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset.stats(include_media=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session = fo.launch_app(view, auto=False)\n",
    "#session.open_tab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "view.filter_field(\"ground_truth\", F(\"detections\").length() == 0).tag_samples(\"no detections\")\n",
    "len(view.match_tags(\"no detections\")) / len(view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_det = view.match_tags(\"no detections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "view = view.exclude(no_det)\n",
    "# session.view = view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_good = view.match_tags(\"no_good\")\n",
    "view = view.exclude(no_good)\n",
    "session.view = view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_train = fo.load_dataset('mva2023_sod4bird_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_all = dataset_train.clone(name='mva2023_sod4bird')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_all.merge_samples(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset.persistent = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = dataset_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "view = dataset.view()\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "view"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8n.pt\")\n",
    "#model.to(\"cuda:0\")\n",
    "\n",
    "pred_field = \"predictions_person\"\n",
    "no_person = view.match_tags(\"no_person_detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_yolo_predictions(view: fo.DatasetView, model: YOLO) -> None:\n",
    "    for sample in no_person.iter_samples(progress=True, autosave=True):\n",
    "        results = model.predict(sample.filepath, augment=True, verbose=False, device=0, imgsz=416, conf=0.5, classes=0)[0]\n",
    "\n",
    "        detections = []\n",
    "        for box in results.boxes:\n",
    "            x_min, y_min, x_max, y_max = box.xyxyn[0]\n",
    "            detection = fo.Detection(\n",
    "                label=model.names[box.cls.item()],\n",
    "                bounding_box=[x_min, y_min, x_max - x_min, y_max - y_min],\n",
    "                confidence=box.conf.item(),\n",
    "            )\n",
    "            detections.append(detection)\n",
    "        sample[pred_field] = fo.Detections(detections=detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if dataset.has_sample_field(pred_field):\n",
    "#     dataset.delete_sample_field(pred_field)\n",
    "\n",
    "if not dataset.has_field(pred_field):\n",
    "    add_yolo_predictions(dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset.delete_sample_field(\"predictions_person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "view.untag_samples(\"no_person_detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_yolo_pred_to_ground_truth(view: fo.DatasetView, model: YOLO) -> None:  \n",
    "    for sample in no_person.iter_samples(progress=True, autosave=True):\n",
    "        results = model.predict(sample.filepath, augment=True, verbose=False, device=0, imgsz=416, conf=0.5, classes=0)[0]\n",
    "\n",
    "        detections = []\n",
    "        for box in results.boxes:\n",
    "            x_min, y_min, x_max, y_max = box.xyxyn[0]\n",
    "            detection = fo.Detection(\n",
    "                label=model.names[box.cls.item()],\n",
    "                bounding_box=[x_min, y_min, x_max - x_min, y_max - y_min],\n",
    "                confidence=box.conf.item(),\n",
    "            )\n",
    "            sample['ground_truth']['detections'].append(detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "add_yolo_pred_to_ground_truth(dataset, model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дубликаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not dataset.has_field(\"filehash\"):\n",
    "    for sample in dataset.iter_samples(progress=True, autosave=True):\n",
    "        sample[\"filehash\"] = fou.compute_filehash(sample.filepath)\n",
    "\n",
    "    filehash_counts = collections.Counter(sample.filehash for sample in dataset)\n",
    "    duplicates_hashes = [filehash\n",
    "                         for filehash, count in filehash_counts.items() if count > 1]\n",
    "    dataset.match(F(\"filehash\").is_in(duplicates_hashes)).tag_samples(\"duplicates\")\n",
    "\n",
    "duplicates = dataset.match_tags(\"duplicates\")\n",
    "# session.view = duplicates.sort_by(\"filehash\")\n",
    "len(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "view = view.exclude(duplicates)\n",
    "session.view = view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "view = dataset.view()\n",
    "session.view = view"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отношение сторон изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install ipywidgets==7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot = fo.NumericalHistogram(F(\"metadata.width\") / F(\"metadata.height\"))\n",
    "#session.plots.attach(plot)\n",
    "plot.show(title=\"Отношение сторон изображений\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if dataset.has_field(\"image_embeddings\"):\n",
    "#     dataset.delete_sample_field(\"image_embeddings\")\n",
    "\n",
    "if not dataset.has_field(\"image_embeddings\"):\n",
    "    model_name = \"clip-vit-base32-torch\"\n",
    "    # model_name = \"mobilenet-v2-imagenet-torch\"\n",
    "\n",
    "    model = foz.load_zoo_model(model_name)\n",
    "    dataset.compute_embeddings(model, embeddings_field=\"image_embeddings\", batch_size=8, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.has_field(\"image_embeddings\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Похожие изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#if not dataset.get_field(\"uniqueness\"):\n",
    "fob.compute_uniqueness(dataset, embeddings=\"image_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.ecdf(view.values(\"uniqueness\"), ecdfnorm=None, title=\"Uniqueness CDF\")\n",
    "fig.update_layout(xaxis_title=\"uniqueness\", yaxis_title=\"samples\", showlegend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "similar_images_view = view.filter_field(\"uniqueness\", F() < 0.3)\n",
    "#session.view = similar_images_view.sort_by(\"uniqueness\", reverse=True)\n",
    "similar_images_view.count(), view.exclude(similar_images_view).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view = similar_images_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "view = view.exclude(similar_images_view)\n",
    "session.view = view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "view = dataset.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Визуализация эмбеддингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip show jupyterlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip show ipywidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pip -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install importlib_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version, PackageNotFoundError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fiftyone -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.has_brain_run(\"image_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if dataset.has_brain_run(\"image_embeddings\"):\n",
    "#     dataset.delete_brain_run(\"image_embeddings\")\n",
    "\n",
    "if not dataset.has_brain_run(\"image_embeddings\"):\n",
    "    fob.compute_visualization(\n",
    "        view, embeddings=\"image_embeddings\", brain_key=\"image_embeddings\", num_dims=2, num_workers=8, seed=0\n",
    "    )\n",
    "results = dataset.load_brain_results(\"image_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot = results.visualize(axis_equal=True)\n",
    "session.plots.attach(plot)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.match_tags('yes')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Обработка классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset.distinct(\"ground_truth.detections.label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"bird\"\n",
    "]\n",
    "\n",
    "view = view.filter_labels(\"ground_truth\", F(\"label\").is_in(classes))\n",
    "view.distinct(\"ground_truth.detections.label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_map = {label: \"vehicle\" for label in view.distinct(\"ground_truth.detections.label\")}\n",
    "view = view.map_labels(\"ground_truth\", labels_map)\n",
    "session.view = view"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Перекрывающиеся детекции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not any(dataset.values(\"ground_truth.detections.max_iou\", unwind=True)):\n",
    "    compute_max_ious(view, \"ground_truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot = fo.NumericalHistogram(\"ground_truth.detections.max_iou\")\n",
    "session.plots.attach(plot)\n",
    "plot.show(title=\"Максимальное пересечение детекций\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "overlapping_view = view.filter_labels(\"ground_truth\", F(\"max_iou\") > 0.6)\n",
    "session.view = overlapping_view\n",
    "len(overlapping_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# view = view.exclude(overlapping_view)\n",
    "session.view = view"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Площадь объектов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not dataset.has_field(\"ground_truth.detections.bbox_area\"):\n",
    "    dataset.add_sample_field(\"ground_truth.detections.bbox_area\", fo.FloatField)\n",
    "view = view.set_field(\"ground_truth.detections.bbox_area\", 100 * F(\"bounding_box\")[2] * F(\"bounding_box\")[3])\n",
    "session.view = view.sort_by(\"ground_truth.detections.bbox_area\", reverse=False)\n",
    "\n",
    "plot = fo.NumericalHistogram(\"ground_truth.detections.bbox_area\", bins=100, xlabel=\"percent\")\n",
    "session.plots.attach(plot)\n",
    "plot.show(title=\"Площадь детекций\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Центры детекций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "center_x = view.values(\n",
    "    F(\"ground_truth.detections.bounding_box\")[0] + F(\"ground_truth.detections.bounding_box\")[2] / 2, unwind=True\n",
    ")\n",
    "center_y = view.values(\n",
    "    F(\"ground_truth.detections.bounding_box\")[1] + F(\"ground_truth.detections.bounding_box\")[3] / 2, unwind=True\n",
    ")\n",
    "points = list(zip(center_x, center_y))\n",
    "\n",
    "sizes = view.values(F(\"ground_truth.detections.bbox_area\"), unwind=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot = fo.scatterplot(points, sizes=sizes)\n",
    "aspect_ratio = np.divide(dataset.values(\"metadata.width\"), dataset.values(\"metadata.height\")).mean()\n",
    "plot.show(title=\"Центры детекций\", width=800, height=800 / aspect_ratio)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Разбивка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#final_dataset_dir = Path(\"/workspace/storage_labs/3030/MukhametshinR/data/vehicle-analytics/final-detection/yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = dataset.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view = view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse = view.match_tags(\"sparse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split, extra_split = train_test_split(sparse.values(\"id\"), test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = dataset.view()\n",
    "sparse = view.match_tags(\"sparse2\")\n",
    "train_split, extra2_split = train_test_split(sparse.values(\"id\"), test_size=0.7, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = dataset.view()\n",
    "sparse = view.match_tags(\"sparse3\")\n",
    "train_split, extra3_split = train_test_split(sparse.values(\"id\"), test_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.select(extra_split).tag_samples(\"extra\")\n",
    "view.select(extra2_split).tag_samples(\"extra\")\n",
    "view.select(extra3_split).tag_samples(\"extra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "view.untag_samples([\"train\", \"val\", \"test\"])\n",
    "\n",
    "train_split, val_split = train_test_split(view.values(\"id\"), test_size=0.15, random_state=0)\n",
    "#val_split, test_split = train_test_split(test_split, test_size=2 / 3, random_state=0)\n",
    "\n",
    "view.select(train_split).tag_samples(\"train\")\n",
    "#view.select(test_split).tag_samples(\"test\")\n",
    "view.select(val_split).tag_samples(\"val\")\n",
    "\n",
    "# assert not dataset.match_tags(\"train\").match_tags(\"test\")\n",
    "# assert not dataset.match_tags(\"train\").match_tags(\"val\")\n",
    "# assert not dataset.match_tags(\"val\").match_tags(\"test\")\n",
    "\n",
    "view.count_sample_tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_dataset_dir = Path('/workspace/storage/db/ppe/set13_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# view.export(\n",
    "#     export_dir=str(final_dataset_dir),\n",
    "#     dataset_type=fo.types.YOLOv5Dataset,\n",
    "#     split=\"kitti\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.view = view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_det = view.match_tags(\"no detections\")\n",
    "bad = view.match_tags(\"bad\")\n",
    "extra = view.match_tags(\"extra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_set = view.exclude(no_det).exclude(bad).exclude(extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '/workspace/storage/3030/VoynovD/dump/data/landfill_set_part15'\n",
    "\n",
    "for split in [\"train\"]:\n",
    "    filepaths = [\"./images/\" + Path(path).parts[-2] + '/' + Path(path).name for path in my_set.match_tags(split).values(\"filepath\")]\n",
    "\n",
    "    split_file = Path(dataset_dir) / f\"{split}_corr.txt\"\n",
    "\n",
    "    split = pd.DataFrame()\n",
    "    if split_file.exists():\n",
    "        split = pd.read_csv(split_file, names=[\"filepath\"])\n",
    "    split = pd.concat((split, pd.DataFrame({\"filepath\": filepaths})), axis=0)\n",
    "\n",
    "    split.to_csv(split_file, index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in [\"train\", 'val']:\n",
    "    filepaths = [\"./images/\" + Path(path).parts[-2] + '/' + Path(path).name for path in view.match_tags(split).values(\"filepath\")]\n",
    "\n",
    "    split_file = Path(dataset_dir) / f\"{split}_clear.txt\"\n",
    "\n",
    "    split = pd.DataFrame()\n",
    "    if split_file.exists():\n",
    "        split = pd.read_csv(split_file, names=[\"filepath\"])\n",
    "    split = pd.concat((split, pd.DataFrame({\"filepath\": filepaths})), axis=0)\n",
    "\n",
    "    split.to_csv(split_file, index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in ['train']:\n",
    "    filepaths = [\"./images/\" + Path(path).name for path in view.match_tags(split).values(\"filepath\")]\n",
    "\n",
    "    split_file = Path(dataset_dir) / f\"train_clear.txt\"\n",
    "\n",
    "    split = pd.DataFrame()\n",
    "    if split_file.exists():\n",
    "        split = pd.read_csv(split_file, names=[\"filepath\"])\n",
    "    split = pd.concat((split, pd.DataFrame({\"filepath\": filepaths})), axis=0)\n",
    "\n",
    "    split.to_csv(split_file, index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for split in [\"train\", \"val\"]:\n",
    "    filepaths = [f\"./images/{split}/\" + Path(path).name for path in view.match_tags(split).values(\"filepath\")]\n",
    "\n",
    "    # split_file = final_dataset_dir / f\"{split}.txt\"\n",
    "\n",
    "    # split = pd.DataFrame()\n",
    "    # if split_file.exists():\n",
    "    #     split = pd.read_csv(split_file, names=[\"filepath\"])\n",
    "    # split = pd.concat((split, pd.DataFrame({\"filepath\": filepaths})), axis=0)\n",
    "\n",
    "    # split.to_csv(split_file, index=None, header=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#classes = ['person']\n",
    "export_dir = \"/workspace/storage/3030/VoynovD/dump/data/extrabird/mva2023_sod4bird_train_yolo\"\n",
    "view.export(\n",
    "    export_dir=export_dir,\n",
    "    dataset_type=fo.types.YOLOv5Dataset,\n",
    "    #split=split,\n",
    "    label_field=\"detections\",\n",
    "    #classes=classes,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "high_resolution = view.match_tags(\"high_resolution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "view = view.exclude(high_resolution)\n",
    "session.view = view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "view.match_tags(\"test\").tag_samples(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "view.untag_samples(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session.view = view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_dataset = view.clone(name=\"set13_v2\")\n",
    "new_dataset.persistent = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#classes = ['person']\n",
    "splits = [\"train\", \"val\"]\n",
    "export_dir = \"/workspace/storage/3030/VoynovD/dump/data/bird_set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for split in splits:\n",
    "    _set= view.match_tags(split)\n",
    "    print(f'{split} = {len(_set)} samples')\n",
    "    \n",
    "    _set.export(\n",
    "    export_dir=export_dir,\n",
    "    dataset_type=fo.types.YOLOv5Dataset,\n",
    "    split=split,\n",
    "    label_field=\"ground_truth\",\n",
    "    classes=classes,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Export **only** labels in the `ground_truth` field in COCO format\n",
    "# with absolute image filepaths in the labels\n",
    "for split in splits:\n",
    "    _set= view.match_tags(split)\n",
    "    print(f'{split} = {len(_set)} samples')\n",
    "\n",
    "    _set.export(\n",
    "        dataset_type=fo.types.COCODetectionDataset,\n",
    "        #export_dir=export_dir,\n",
    "        labels_path=f\"{export_dir}/annotations/{split}.json\",\n",
    "        label_field=\"ground_truth\",\n",
    "        #abs_paths=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(fo.list_datasets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "view = view.match_tags(\"good\")\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_dataset_dir = Path('/workspace/storage/db/emergency-search/uzaodd_clear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepaths = [f\"./images/\" + Path(path).name for path in view.values(\"filepath\")]\n",
    "\n",
    "split_file = final_dataset_dir / \"train_good.txt\"\n",
    "\n",
    "split = pd.DataFrame()\n",
    "if split_file.exists():\n",
    "    split = pd.read_csv(split_file, names=[\"filepath\"])\n",
    "split = pd.concat((split, pd.DataFrame({\"filepath\": filepaths})), axis=0)\n",
    "\n",
    "split.to_csv(split_file, index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    filepaths = [f\"./images/{split}/\" + Path(path).name for path in view.match_tags(split).values(\"filepath\")]\n",
    "\n",
    "    split_file = final_dataset_dir / \"train_clear.txt\"\n",
    "\n",
    "    split = pd.DataFrame()\n",
    "    if split_file.exists():\n",
    "        split = pd.read_csv(split_file, names=[\"filepath\"])\n",
    "    split = pd.concat((split, pd.DataFrame({\"filepath\": filepaths})), axis=0)\n",
    "\n",
    "    split.to_csv(split_file, index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fo.delete_dataset('WiSARDv1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_dataset.default_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "view = new_dataset.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
